# Axivity-Sensor
Tool to analyse and label Axivity sensor output

The Axivity AX3 accelerometer is a wearable sensor that measures acceleration values in 3 orthogonal directions - x, y and z.

This code has three basic functions :   
  Label output csv records from the sensor by activity types performed by a user   
  Build machine learning models using the labelled data for automatic recognition of activity type   
  Run these models against unlabelled csv files from the sensor to automatically label them    
  
Requirements : Python, plus required libraries (see 'loadLibraries' function) which can be obtained using 'pip install', eg pip install csv  
Note : 'pip install pyyaml h5py' is needed for Neural Network processing.  
On running the code, if any required libraries are not present for the selected processing, a message is output for each one missing, and the run terminates.
  
To run :  
  python axivityProcess.py  

Configuration of the sensor is performed using the 'Open Movement' (OM) software package that accompanies it, via a USB or wireless connection to a computer.
Recording of data is started using OM, activities are undertaken by a user, then recording is stopped in OM.
A compressed data file of type 'cwa' is generated by the sensor, with each record containing a timestamp, acceleration readings in the x, y and z directions,
and temperature readings.
The x, y and z directions will depend on the orientation of the sensor during the time it is recording.
OM has a facility for exporting the resultant 'cwa' files to other file types, such as csv files.
 
This code processes exported files (from OM) of type 'raw csv', with datetime format Y-M-D h-m-s.f, and Accelerometer Units Gravity(g). 
Temperature readings are not processed as they are likely to be of little value for the purpose of predicting activity type.

The user selects from one of nine functions (by specifying the number of the function, as displayed) -
1) Label csv file from sensor                                        
2) Combine labelled csv files                                        
3) Create kMeans model from labelled file                            
4) Create Machine Learning models from labelled file                 
5) Create Neural Network model from labelled file                    
6) Run kMeans model against unlabelled csv file from sensor          
7) Run Machine Learning model against unlabelled csv file from sensor
8) Run Neural Network model against unlabelled csv file from sensor  
9) Help                                                              

For all functions except 'Help', processing starts with the user selecting an input file (by clicking it in a separate Explorer window opened by the code)

When manually labelling a file from the sensor, the output consists of 2 csv files:
  The first has a subject id (eg the user's initials), and an abbreviation of the sensor location (eg 'LW' for Left Wrist) appended to the original file name
  The second has '_sum' appended to this first file name. 
When creating a machine learning model it is saved to a folder specified by the user.
When running a model against an unlabelled file an output file can be created containing predicted activities, again in a location 
selected by the user. This will have the same format as the first file above.  

For 'Label csv file from sensor' :  
The first output file has format :  
  Timestamp  x-val  y-val  z-val  rms-val  activity      
where 'rms-val' is the root mean square of the x, y and z values   
eg 22/02/2022 18:07:16	0.203125	0.28125	-0.9375	0.999633722	Walk Upstairs
 
Note : If the csv files are viewed using Excel, the timestamp values may appear as '########' in the table cells.
       To view them as timestamps :  
          right-click the first cell
          select 'format cells'
          'custom' with 'type' dd/mm/yyyy hh:mm , in the box immediately below 'Type' append ':ss' (for seconds)
          'ok'
(if other datetime formats are used the code will fail to run)

The 'sum' file gives a summary of the means and standard deviations for each block of activity for each of the x, y, z and rms values and how long the activity
lasted in seconds, eg  
Subject Activity        Location   Time             Duration(s)	x mean x std y mean y std z mean z std rms mean	rms std  
NS      Walk Upstairs   Left Wrist 22/02/2022 18:08 66          -0.4   0.32  0.4    0.74  0.03   0.33  1        0.35

Several prompts are displayed for user input :  
The number of readings per second in the file is determined by the code, and the user is prompted to specify how many they wish to retain.
 The sensor can record between 12.5 and 500 readings per second (Hz), but the OM software warns that it may not process signals correctly if the rate
 is set below 50Hz. It is probably best therefore to use this as a minimum frequency value when configuring the sensor. However, this number of readings
 may not be required to determine activity type, eg 10 or 20 readings per second may be sufficient to distinguish between different activities.
A plot is then displayed of the input data, and the user left clicks all the transitions between activities for the time period of interest. When finished they right click.  
If the magnifier tool is used, selected areas to magnify should be defined with y-values well above/below the y-values used to set activity transitions.
These clicks will be discarded afterwards, and not mistaken as transition points.  
A list of activities is shown, and for each time period the user specifies the associated activity.  
Periods for which the user selects 'Other' as the activity type will be discarded (although the stats for them will be included in the ..._sum.csv file).
If the user selects any 'Other' activities, the timestamps of subsequent periods are adjusted to run immediately consecutive to the activity preceding the period for 'Other'.  
The timestamps will no longer be the actual timestamps, but this does not affect using the output files for training models, and using the trained models for predicting activities for unlabelled files.  
The next prompt is for Subject id - eg the initials of the person using the sensor for the selected csv file.   
The user is then asked for the sensor location during the activities, eg on the Left Wrist. It is assumed the same location applies to all activities stored
in the one file. A list of activities is defined at the start of the code, which can easily be edited.  
The output file is then written, with the root mean square value of the x, y and z values, and the associated activity being added to each input record.
Finally, the user can display a plot of the resultant file.  
  
'Combine labelled csv files' produces a single labelled file from multiple input files. This may be useful for combining different files that have been 
created by a user containing different activities. A model can then be trained against the combined file containing all the activity types. 
eg a user might perform 'walk' and 'sit' activities and save them to one file, then perform 'run' and 'drive' and save to a second file, then save 'sleep' to 
a third file. All these can be amalgamated into one output file.  
When training models to recognise activity types the values in timestamp are not used (but the created records should stay in the same chronological order for
reasons of pattern recognition).  
The first input file is simply copied to the output file and the timestamp of the last record in the file is saved.  
One second is added to this saved timestamp, and for the next input file all records are appended to the end of the output file, but with the
timestamps replaced - starting with the (timestamp + 1 second) as the replacement value, and incrementing this by one second each time the 'second' value
changes in the input file. For each subsequent file the modified timestamp is used, adding one second for the start of each file.   
The resultant output file then contains a set of records with all the input activities in a contiguous block (time-wise).  
  
For options 3, 4 and 5 (creating models), after selecting the (labelled) input file, the user selects a parent folder to create the folder in that will contain
the model (from a separate Explorer window, opened by the code), and then they specify the name for the sub-folder for holding the model.  
The number of records in the selected input data is displayed, and the user is asked how many they wish to retain as a random sample from this data set (between 1000
and the total number of records). The more records that are used for training the models, the longer the process takes. The user may wish to experiment with different 
values here.  
They are then asked if they wish to scale the data. Scaling may help prevent large values for one variable from swamping those for the others, but it may also result in worse prediction outcomes if the uniqueness of input patterns is made less distinct. Again, experimentation is required.   
The model is then created in the specified sub-folder (for option 4, 5 models are created).  
  
For options 6, 7 and 8 (using previously created models to process unlabelled files from the sensor), after selecting the (unlabelled) 
input file, the user selects the directory containing the model. They are then shown the activities catered for by the model (the ones
in the file the model was created from) and asked if they wish to continue. If they respond 'N' processing stops. Otherwise a plot is
displayed of the input data and the user selects the start and end times of the data of interest using mouse left clicks
(each input file will have some data at the start and end that should be discarded - when the user is putting the sensor on/taking it off - 
if included this may result in poorer prediction accuracy by the model). 
As for options 3, 4 and 5 the user can restrict the number of data records processed (to reduce run time) and scale/not scale the data - experiment.
A plot of the input data, plus rms and predicted activities is then displayed. Finally the user can produce a labelled file (using the model 
predictions) - they are prompted for the file name to create.  
  
Means of classifying data - most common techniques - KNN, kmeans and sub-clustering. From review paper -
https://www.researchgate.net/publication/341303680_Unsupervised_Human_Activity_Recognition_Using_the_Clustering_Approach_A_Review


